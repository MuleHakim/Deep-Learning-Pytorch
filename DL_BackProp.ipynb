{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPQCAoVkSI8z/CeeoNwsmO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuleHakim/Deep-Learning-Pytorch/blob/main/DL_BackProp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYjTHIb4sMYk"
      },
      "outputs": [],
      "source": [
        "# !pip install torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load MNIST dataset using torchvision\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "\n",
        "# Create DataLoader for training and testing sets\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Extract one batch of data for training\n",
        "for images, labels in trainloader:\n",
        "  break\n",
        "\n",
        "# Flatten the images\n",
        "X_train = images.view(images.shape[0], -1).numpy()\n",
        "y_train_onehot = np.eye(10)[labels.numpy()]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights, and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n"
      ],
      "metadata": {
        "id": "d8jaGenvysnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU activation\n",
        "class Activation_ReLU:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Since we need to modify the original variable,\n",
        "        # let's make a copy of values first\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "cUZSC2qvy0OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient and add it to the array of sample gradients\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
        "\n"
      ],
      "metadata": {
        "id": "h5P2f1AGy3_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common loss class\n",
        "class Loss:\n",
        "\n",
        "    # Calculates the data and regularization losses\n",
        "    # given model output and ground truth values\n",
        "    def calculate(self, output, y):\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "        # Calculate mean loss\n",
        "        data_loss = np.mean(sample_losses)\n",
        "        # Return loss\n",
        "        return data_loss\n",
        "\n",
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # Number of samples in a batch\n",
        "        samples = len(y_pred)\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of labels in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        labels = len(dvalues[0])\n",
        "        # If labels are sparse, turn them into a one-hot vector\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n"
      ],
      "metadata": {
        "id": "f5OHaEkDy7zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax classifier - combined Softmax activation\n",
        "# and cross-entropy loss for faster backward step\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "\n",
        "    # Creates activation and loss function objects\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, y_true):\n",
        "        # Output layer's activation function\n",
        "        self.activation.forward(inputs)\n",
        "        # Set the output\n",
        "        self.output = self.activation.output\n",
        "        # Calculate and return loss value\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # If labels are one-hot encoded,\n",
        "        # turn them into discrete values\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        # Copy so we can safely modify\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Calculate gradient\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples"
      ],
      "metadata": {
        "id": "HExdPt8czCnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joiWG84uzGJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dense layer with 784 input features and 64 output values\n",
        "dense1 = Layer_Dense(784, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 64 input features (as we take output\n",
        "# of the previous layer here) and 10 output values (output values)\n",
        "dense2 = Layer_Dense(64, 10)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "# Perform a forward pass of our training data through this layer\n",
        "dense1.forward(X_train)\n",
        "\n",
        "# Perform a forward pass through activation function\n",
        "# takes the output of the first dense layer here\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "# Perform a forward pass through the second Dense layer\n",
        "# takes outputs of the activation function of the first layer as inputs\n",
        "dense2.forward(activation1.output)\n",
        "\n",
        "# Perform a forward pass through the activation/loss function\n",
        "# takes the output of the second dense layer here and returns loss\n",
        "loss = loss_activation.forward(dense2.output, y_train_onehot)\n",
        "\n"
      ],
      "metadata": {
        "id": "6KxXHtX4sO47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the output of the first few samples:\n",
        "print(loss_activation.output[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YByfut2AzMVw",
        "outputId": "e06a7f6c-ba80-4b97-8c6d-6f74874485a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.10111312 0.10091501 0.10065762 0.10011536 0.09881388 0.09770232\n",
            "  0.10018043 0.09959669 0.10178134 0.09912422]\n",
            " [0.10082201 0.09948633 0.10008114 0.1007011  0.0996671  0.09969102\n",
            "  0.10205675 0.09843529 0.09929668 0.0997626 ]\n",
            " [0.10119645 0.10270662 0.10202328 0.09993858 0.09920311 0.09740989\n",
            "  0.10138436 0.09867394 0.100573   0.09689078]\n",
            " [0.10105929 0.10072766 0.10134901 0.10048848 0.09819008 0.09871686\n",
            "  0.10044242 0.09919836 0.10169274 0.09813509]\n",
            " [0.10086254 0.10078634 0.10061818 0.10069984 0.09770212 0.09946223\n",
            "  0.10114631 0.09855743 0.10244274 0.09772225]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print loss value\n",
        "print('loss:', loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg6LffcYzPYV",
        "outputId": "34553ce3-ba63-4b5e-8834-e6ca8cf4cac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.3023723824524893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy from the output of activation2 and targets\n",
        "# calculate values along the first axis\n",
        "predictions = np.argmax(loss_activation.output, axis=1)\n",
        "if len(y_train_onehot.shape) == 2:\n",
        "    y_train = np.argmax(y_train_onehot, axis=1)\n",
        "\n",
        "accuracy = np.mean(predictions == y_train)\n",
        "\n",
        "# Print accuracy\n",
        "print('acc:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmRWk4rDzSe6",
        "outputId": "919828e0-0f81-4491-feb4-eb74445f2d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.109375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward pass\n",
        "loss_activation.backward(loss_activation.output, y_train_onehot)\n",
        "dense2.backward(loss_activation.dinputs)\n",
        "activation1.backward(dense2.dinputs)\n",
        "dense1.backward(activation1.dinputs)\n",
        "\n",
        "# Print gradients\n",
        "print(\"Gradients for dense1:\")\n",
        "print(dense1.dweights)\n",
        "print(dense1.dbiases)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QkVlP-szVzu",
        "outputId": "b36d3592-4516-45e8-bac3-4815084d0e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients for dense1:\n",
            "[[ 9.65431940e-06 -9.20002167e-05  7.43459472e-05 ...  2.26045102e-05\n",
            "  -1.32089985e-03  1.36385469e-04]\n",
            " [ 9.65431940e-06 -9.20002167e-05  7.43459472e-05 ...  2.26045102e-05\n",
            "  -1.32089985e-03  1.36385469e-04]\n",
            " [ 9.65431940e-06 -9.20002167e-05  7.43459472e-05 ...  2.26045102e-05\n",
            "  -1.32089985e-03  1.36385469e-04]\n",
            " ...\n",
            " [ 9.65431940e-06 -9.20002167e-05  7.43459472e-05 ...  2.26045102e-05\n",
            "  -1.32089985e-03  1.36385469e-04]\n",
            " [ 9.65431940e-06 -9.20002167e-05  7.43459472e-05 ...  2.26045102e-05\n",
            "  -1.32089985e-03  1.36385469e-04]\n",
            " [ 9.65431940e-06 -9.20002167e-05  7.43459472e-05 ...  2.26045102e-05\n",
            "  -1.32089985e-03  1.36385469e-04]]\n",
            "[[-9.65431940e-06  9.20002167e-05 -7.43459472e-05  2.28283573e-04\n",
            "   5.71201096e-04  6.65137772e-04 -1.27935077e-03  8.42257423e-04\n",
            "  -2.03235627e-04 -2.52281249e-05 -1.32723750e-03 -4.05878173e-04\n",
            "   1.09031355e-03  0.00000000e+00 -6.22409527e-04  5.76867796e-05\n",
            "   9.95725165e-04 -4.17804313e-04 -3.87026180e-04  0.00000000e+00\n",
            "  -1.47573543e-03  8.88136005e-04  1.82485936e-04 -1.00972825e-03\n",
            "   4.16554497e-05 -5.41807249e-04  5.02857407e-04  7.06048397e-04\n",
            "   6.65095065e-04  8.58084287e-04 -1.94004190e-03 -6.98610099e-04\n",
            "  -1.15622812e-03  3.67086047e-05  2.58270808e-03  3.16364537e-04\n",
            "   1.07204794e-04  1.68732100e-03  6.36536135e-04 -7.62061501e-04\n",
            "   1.38082731e-03  1.47800771e-03 -8.03302646e-04 -6.95867069e-04\n",
            "  -8.79729353e-04  7.82327560e-05 -4.92379865e-05 -6.75233137e-04\n",
            "  -9.29892509e-04 -1.08502665e-03 -7.71270187e-04  5.68555703e-04\n",
            "  -8.62941339e-04  1.16500835e-03 -1.49967879e-04  1.39463259e-04\n",
            "  -1.96160009e-05  5.38004363e-04 -1.01163957e-03  8.73956170e-04\n",
            "  -8.29586463e-05 -2.26045102e-05  1.32089985e-03 -1.36385469e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Gradients for dense2:\")\n",
        "print(dense2.dweights)\n",
        "print(dense2.dbiases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHYhXYUczX7U",
        "outputId": "e5aefe26-3e0e-459e-c6fb-e22b20f4bb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients for dense2:\n",
            "[[-9.02533441e-03  1.65711735e-03  3.21885182e-03  3.35283241e-03\n",
            "   2.79906366e-03  1.50049864e-03 -6.09835165e-03  1.28364283e-03\n",
            "   2.14723035e-04  1.09695632e-03]\n",
            " [-1.07281648e-03  1.35648662e-03 -4.81198385e-03 -1.30135048e-03\n",
            "   7.46620543e-04  1.34299721e-03  1.12170715e-03  3.25758673e-04\n",
            "   1.36333012e-03  9.29250493e-04]\n",
            " [ 1.94002476e-04  1.91374804e-04 -1.38721888e-03 -1.53955121e-04\n",
            "   1.90918741e-04  1.93065761e-04  1.93148502e-04  1.93216860e-04\n",
            "   1.97638904e-04  1.87807957e-04]\n",
            " [ 6.18731830e-05  6.22104842e-05  6.15499764e-05  6.10389899e-05\n",
            "  -5.53375903e-04  5.99911813e-05  6.24230186e-05  6.09227996e-05\n",
            "   6.18362548e-05  6.15300153e-05]\n",
            " [ 2.16549823e-02  9.81743255e-03 -3.60243385e-02 -5.98276643e-03\n",
            "   1.32352053e-02 -3.28660721e-03 -1.27918864e-02  1.60798294e-02\n",
            "  -7.65117457e-04 -1.93673364e-03]\n",
            " [ 7.58190159e-03  1.26973592e-02 -2.21478534e-02 -1.85631611e-02\n",
            "   1.50471298e-02 -2.07814735e-03 -5.82052747e-03  1.49126044e-02\n",
            "   9.26579346e-03 -1.08950991e-02]\n",
            " [-3.36874363e-03  4.98671342e-03 -1.58903937e-02  5.33365215e-03\n",
            "   7.31202003e-03  6.45405132e-03 -1.00493204e-03 -2.15966811e-04\n",
            "   1.32437576e-02 -1.68501584e-02]\n",
            " [-2.07700392e-04  1.80237929e-02  1.20760258e-02  1.98062887e-03\n",
            "   4.07512232e-03 -2.50198371e-03 -1.16926127e-03 -8.20897725e-03\n",
            "   1.26255832e-02 -3.66932304e-02]\n",
            " [-1.14894261e-03  6.33640604e-04  1.00947252e-05 -4.69504917e-04\n",
            "   6.26045135e-04  6.15718659e-04  6.30713841e-04 -1.80015922e-04\n",
            "   6.41702614e-04 -1.35945213e-03]\n",
            " [ 9.12127633e-05  9.16708720e-05  9.01060752e-05  9.01131433e-05\n",
            "   8.96557618e-05  8.84567629e-05 -8.13125784e-04  9.07798855e-05\n",
            "   9.13637952e-05  8.97667249e-05]\n",
            " [ 3.01718585e-03  3.01120181e-03 -1.00409450e-02  1.65668547e-03\n",
            "   1.81501267e-03 -5.91681601e-03  3.04324717e-03  2.97135213e-03\n",
            "   1.83864313e-03 -1.39556721e-03]\n",
            " [ 9.77831402e-05  9.82090830e-05  9.65474850e-05  9.15994500e-05\n",
            "   9.57192612e-05  9.59737115e-05  9.86552824e-05  9.74723274e-05\n",
            "  -8.67507250e-04  9.55475092e-05]\n",
            " [-2.18474711e-04  1.02524586e-02 -2.87677927e-03 -1.76575672e-02\n",
            "   5.51734090e-03 -1.41370725e-02 -1.88600809e-03  1.01629517e-02\n",
            "   6.68117413e-03  4.16197645e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 1.43410267e-02  7.26160620e-04 -9.19746316e-03 -1.21042024e-02\n",
            "   3.75130722e-03  1.88571925e-03 -1.02950236e-02  8.73695769e-03\n",
            "   3.33575125e-03 -1.18023362e-03]\n",
            " [ 4.20405622e-05  4.26701365e-05  4.22063118e-05  4.17747517e-05\n",
            "   4.14548699e-05  4.05049146e-05  4.19996061e-05  4.14445310e-05\n",
            "   4.22344794e-05 -3.76330163e-04]\n",
            " [ 2.39566447e-03  9.57388215e-03  5.75411469e-04 -5.13979896e-03\n",
            "   4.18048796e-03 -6.58209820e-03 -5.40183654e-03  2.85560284e-03\n",
            "   7.64623250e-03 -1.01035477e-02]\n",
            " [ 1.14358511e-02  3.87628248e-03 -2.71395481e-04 -1.66391318e-02\n",
            "   2.06584504e-03 -6.95197634e-03 -2.16382766e-03  1.24347871e-03\n",
            "   3.71919964e-03  3.68567433e-03]\n",
            " [ 1.04375586e-02  1.12610491e-03 -7.46692813e-03  4.39020984e-03\n",
            "   2.41612303e-03 -4.37228361e-03 -5.94341852e-03  7.56735137e-03\n",
            "   3.61034365e-04 -8.51575182e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 4.42573462e-03  3.49979460e-03  3.87851419e-03  1.56495173e-03\n",
            "  -1.61468884e-03 -3.81055271e-04 -3.19206959e-03  1.34432442e-03\n",
            "  -3.99025456e-05 -9.48560331e-03]\n",
            " [-1.83101226e-03 -2.11635649e-03 -1.45435220e-03 -8.20665708e-03\n",
            "   3.70675739e-03  1.60857563e-03  3.76810743e-03  8.13432252e-05\n",
            "   3.80348957e-03  6.40104791e-04]\n",
            " [ 2.02084683e-02  1.87959309e-02 -1.73849512e-02 -1.17693159e-02\n",
            "   7.84476266e-03 -1.47299141e-02 -1.79792315e-04  1.79722363e-02\n",
            "  -1.10574254e-02 -9.69999931e-03]\n",
            " [ 2.00202446e-02  2.63383787e-03 -1.84749743e-02 -5.90126293e-03\n",
            "   1.00880628e-02  6.92225234e-03 -1.49711433e-02  7.46190683e-03\n",
            "   3.50254030e-04 -8.12917794e-03]\n",
            " [ 1.20185774e-02  1.24376275e-02 -1.43290249e-02 -4.16744628e-02\n",
            "   1.30112027e-02 -8.72086472e-03  2.17502691e-03  1.64342666e-02\n",
            "   4.88182093e-04  8.15946907e-03]\n",
            " [ 6.67214870e-03  3.74835686e-03  5.82008862e-03 -7.32937120e-03\n",
            "  -8.48721167e-04 -2.75932176e-03  1.28943217e-03  4.78767817e-03\n",
            "   4.20965052e-03 -1.55899409e-02]\n",
            " [ 5.52642670e-03  2.71526006e-03 -9.60848385e-03  5.49459899e-03\n",
            "   4.62088557e-03 -3.63134409e-03 -9.94659107e-03  4.03597512e-03\n",
            "   3.63197465e-03 -2.83870208e-03]\n",
            " [ 2.19595380e-02  1.43379440e-02 -4.18874643e-02 -4.85730119e-03\n",
            "   7.65249849e-03  1.11841183e-03 -1.82923091e-02  2.40557475e-02\n",
            "  -1.33123609e-03 -2.75582914e-03]\n",
            " [ 4.05553337e-03  5.90298952e-03  2.54830136e-04 -7.18630028e-03\n",
            "   5.53628756e-03 -9.15786081e-03  1.50862190e-03 -4.18587514e-03\n",
            "   8.26449729e-03 -4.99272354e-03]\n",
            " [ 7.76840069e-03  7.83941946e-03  4.41448768e-04 -1.84985233e-02\n",
            "   1.56477586e-03 -2.74069180e-03  5.51799876e-05  2.52065371e-03\n",
            "   4.24888246e-03 -3.19954582e-03]\n",
            " [ 2.19867331e-03  6.77252348e-03 -2.42792996e-03 -7.78166030e-03\n",
            "   5.34216646e-03 -4.37126071e-03  5.31246377e-03  4.70001235e-03\n",
            "  -3.03352333e-03 -6.71146508e-03]\n",
            " [ 6.34766737e-03  3.73611118e-03  4.41353963e-03 -6.44582809e-03\n",
            "  -2.14207760e-03 -4.02051006e-03  1.08592129e-05  5.46988395e-03\n",
            "  -2.76308858e-03 -4.60655703e-03]\n",
            " [ 1.15965930e-02  3.23049910e-03 -2.10854369e-02 -1.98374180e-02\n",
            "   9.53302061e-03 -3.16295743e-03  3.76551232e-03  1.29775194e-02\n",
            "  -9.35877285e-03  1.23414407e-02]\n",
            " [ 1.55495707e-04  1.53435723e-04 -1.38792636e-03  1.55309231e-04\n",
            "   1.53714513e-04  1.53751415e-04  1.57400027e-04  1.51814722e-04\n",
            "   1.53143221e-04  1.53861801e-04]\n",
            " [ 3.10899443e-03  1.01036707e-02 -2.81488322e-04 -3.23114048e-02\n",
            "   1.37581805e-02 -8.51324001e-03  7.30394562e-04  2.05493224e-02\n",
            "  -4.20214399e-04 -6.72421509e-03]\n",
            " [ 6.01117191e-05  5.95822354e-05  6.04207367e-05  5.94308317e-05\n",
            "   5.88068067e-05  5.80692583e-05  5.91962582e-05 -5.34370537e-04\n",
            "   5.98264449e-05  5.89262457e-05]\n",
            " [ 5.77047300e-05  5.66326471e-05  5.69900513e-05  5.75387939e-05\n",
            "   5.60412497e-05  5.70380463e-05  5.78136777e-05  5.66758848e-05\n",
            "  -5.12962103e-04  5.65270221e-05]\n",
            " [ 2.63203467e-02  1.53450862e-02 -1.21462337e-03 -7.41814093e-03\n",
            "   4.77415200e-03 -7.01431492e-03 -1.16955835e-02  4.29982973e-03\n",
            "   1.41633283e-02 -3.75600803e-02]\n",
            " [-3.97912320e-04  8.75664882e-04  4.15061394e-05  6.58451236e-04\n",
            "   8.56461441e-04  5.30003737e-04  8.05533072e-04  8.62160197e-04\n",
            "  -8.88562763e-04 -3.34330562e-03]\n",
            " [ 2.43193946e-02  3.28818787e-03 -1.95328034e-02 -2.10350586e-02\n",
            "   1.06429403e-02 -1.80574153e-03  1.85392451e-03  1.37147242e-02\n",
            "  -3.18958696e-03 -8.25598097e-03]\n",
            " [ 1.99242175e-02  9.77198003e-03 -2.33174714e-02 -4.41730538e-03\n",
            "   9.07215513e-03 -3.66254569e-03 -5.48004294e-03  1.12574379e-02\n",
            "  -2.75080034e-03 -1.03976248e-02]\n",
            " [ 4.30837946e-03  2.57016837e-03 -7.39917313e-03 -7.12966180e-03\n",
            "  -4.55718902e-04 -3.82999801e-03  3.17965750e-03  3.11430268e-03\n",
            "   3.06050586e-03  2.58153797e-03]\n",
            " [ 4.67453352e-03 -9.98652704e-04 -4.91154174e-03  1.96839707e-03\n",
            "   2.60169587e-03 -6.60450435e-03 -1.95501820e-03  5.52265672e-03\n",
            "  -5.73878912e-03  5.44122294e-03]\n",
            " [-2.29962670e-03  1.11881826e-02 -2.00897779e-02 -4.86746024e-03\n",
            "   8.92507451e-03 -2.04757471e-03  1.81795721e-03  1.11244495e-02\n",
            "  -9.54045194e-03  5.78922763e-03]\n",
            " [ 1.02833004e-02  1.41634715e-02 -1.35939553e-02 -1.71011272e-02\n",
            "   1.19852656e-02 -4.44132257e-03  2.83436850e-03  1.40099869e-02\n",
            "  -9.83774137e-03 -8.30224664e-03]\n",
            " [-1.24441539e-03  2.31272914e-03 -2.58713692e-03  2.30571455e-03\n",
            "   3.45262984e-04  2.25769112e-03 -2.49231557e-03  1.25122190e-03\n",
            "   1.75307338e-03 -3.90182519e-03]\n",
            " [-2.03776840e-03  2.32605379e-04  2.32606300e-04  1.95814212e-04\n",
            "   2.29595607e-04  2.22590042e-04  2.30703023e-04  2.31804119e-04\n",
            "   2.33859616e-04  2.28190108e-04]\n",
            " [ 2.13914291e-03  2.12704121e-03 -9.13907071e-03 -1.11944171e-03\n",
            "   1.79537010e-03  2.11846986e-03  2.15688096e-03  2.11226855e-03\n",
            "  -4.21569006e-03  2.02502889e-03]\n",
            " [ 2.98337345e-02  3.72453842e-03 -1.85159253e-02 -2.13757467e-02\n",
            "   1.74381762e-02 -7.30424271e-03 -2.45700043e-03  6.09909925e-03\n",
            "   1.11689417e-02 -1.86115749e-02]\n",
            " [-3.15189640e-04  3.11428037e-05 -1.32768382e-03  1.03037148e-03\n",
            "   1.01301101e-03 -4.73867084e-04  1.03685402e-03  4.60493582e-04\n",
            "  -1.84062389e-03  3.85491550e-04]\n",
            " [ 2.08158012e-02  5.67508324e-03 -4.50963116e-03 -1.19831376e-02\n",
            "   1.17989463e-02 -7.24055721e-05 -1.68175582e-02  1.42932096e-02\n",
            "  -3.01970185e-03 -1.61806060e-02]\n",
            " [ 8.53483100e-04  8.51728871e-04  8.45686528e-04 -1.16166020e-03\n",
            "  -1.37444546e-03 -2.59567431e-03  8.58611883e-04  8.47085074e-04\n",
            "   8.59487817e-04  1.56966877e-05]\n",
            " [ 6.94634371e-03  8.86793762e-03 -1.17446316e-02  1.19996033e-03\n",
            "   1.25458077e-02  1.15644322e-03 -7.60749241e-03  3.89322991e-03\n",
            "   8.55044342e-03 -2.38080419e-02]\n",
            " [ 5.98111686e-03 -9.87664373e-03 -8.23092554e-03  3.07430111e-03\n",
            "   6.15480325e-03 -1.27768970e-03 -9.02204778e-03  4.54910571e-03\n",
            "   4.15319578e-03  4.49478405e-03]\n",
            " [ 7.45282641e-04  7.45610172e-04 -4.56384404e-03  7.42701658e-04\n",
            "   7.29916688e-04  7.36816447e-04  7.56212129e-04  7.37130565e-04\n",
            "  -1.36022678e-03  7.30400522e-04]\n",
            " [-2.17082813e-03  4.86732758e-04  4.89927679e-04 -4.24184679e-04\n",
            "   4.86553632e-04  4.53304838e-04  4.85502985e-04 -1.37641815e-04\n",
            "   4.95037981e-04 -1.64405247e-04]\n",
            " [ 7.67126728e-05  7.58275298e-05  7.47667208e-05  7.61485348e-05\n",
            "   7.45766227e-05  7.45290653e-05  7.77480127e-05  7.51682805e-05\n",
            "  -6.80799035e-04  7.53215952e-05]\n",
            " [ 3.99424704e-03  4.02044286e-03 -7.92720685e-03  3.96286035e-03\n",
            "  -1.44869100e-04  3.90052460e-03 -7.57674436e-03  1.87728199e-03\n",
            "   4.03087602e-03 -6.13741255e-03]\n",
            " [ 2.49600802e-02  2.01622314e-02  2.80800040e-03 -9.66612667e-03\n",
            "   3.35085858e-03 -1.55663219e-02 -1.08886994e-02  1.11613309e-02\n",
            "   6.36680522e-03 -3.26881586e-02]\n",
            " [-2.39658455e-03  7.57313955e-03 -7.69550823e-03 -1.12456470e-02\n",
            "   7.53733363e-03  1.99457428e-03  7.66501178e-03 -9.42925104e-04\n",
            "   7.44709011e-04 -3.23410339e-03]\n",
            " [ 4.45056581e-03  1.03646572e-03 -1.00581960e-02 -2.70108151e-02\n",
            "   7.44568366e-03  4.14521683e-03  7.63870436e-03  4.32998362e-03\n",
            "   2.21259800e-03  5.80979307e-03]\n",
            " [ 2.68026486e-03  1.06033961e-06 -1.24827105e-02 -1.39818900e-02\n",
            "   8.71290695e-03 -8.42694610e-03  4.94182987e-03  7.68451179e-03\n",
            "   5.71570808e-03  5.15526473e-03]\n",
            " [ 1.22954333e-03  1.00093375e-03 -1.87191334e-03 -3.05104576e-03\n",
            "   2.42156070e-03  3.01176581e-03  3.55920043e-03 -4.55258531e-03\n",
            "   1.00309994e-04 -1.84776961e-03]\n",
            " [-1.68159334e-03  5.69135939e-04 -2.88089414e-03  5.75327895e-04\n",
            "   5.68315353e-04  5.69082005e-04  5.70657083e-04  5.69953179e-04\n",
            "   5.85942072e-04  5.54073955e-04]]\n",
            "[[ 0.05390048  0.03803011 -0.05620964 -0.05607201  0.03626045 -0.01068048\n",
            "  -0.0081102   0.03696462  0.00765626 -0.0417396 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_imQpENLu7-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}